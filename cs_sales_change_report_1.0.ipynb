{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import zipfile\n",
    "import fnmatch\n",
    "import datetime\n",
    "from zipfile import ZipFile\n",
    "import pandas as pd\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sheet(sheet_list, sheet_name):\n",
    "    \"\"\"\n",
    "    If a workbook matches the desired name\n",
    "    store each worksheet into a list.\n",
    "    \"\"\"\n",
    "    return [x for x in sheet_list if re.search(sheet_name.lower(), x.lower())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_timestamp():\n",
    "    \"\"\"\n",
    "    Creates a timestamp in DB format.\n",
    "    \"\"\"\n",
    "    today = datetime.date.today()\n",
    "    year = today.year\n",
    "    month = today.month\n",
    "    day = today.day\n",
    "    \n",
    "    timestamp = f\"{str(year)}-{str(month)}-{str(day)}\"\n",
    "    \n",
    "    return timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see if package working directories exist.\n",
    "# If the do not, create them.\n",
    "\n",
    "data_dir = \".\\\\excel\\\\data\\\\\"\n",
    "archive_dir = \".\\\\excel\\\\archive\\\\\"\n",
    "\n",
    "if not os.path.exists(archive_dir):\n",
    "    os.makedirs(archive_dir)\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "    # exit() Use in stand-alone script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see if there are existing old Excel files\n",
    "# in the working directory. If they do, delete them.\n",
    "\n",
    "if fnmatch.fnmatch(data_file, \"*.xlsx\") == True:\n",
    "    os.remove(glob.glob(data_dir + \"*.xlsx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see which files are zipped files\n",
    "# in the working directory, then unzip them\n",
    "# and then delete them.\n",
    "\n",
    "for data_file in os.listdir(data_dir):\n",
    "    if fnmatch.fnmatch(data_file, \"*.zip\") == True:\n",
    "        with ZipFile(data_dir + data_file, \"r\") as zip_obj:\n",
    "            zip_obj.extractall(data_dir)\n",
    "        os.remove(data_dir + data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version 1\n",
    "\n",
    "file_list = glob.glob(data_dir + \"*.xlsx\")\n",
    "\n",
    "for xl_file in file_list:\n",
    "    sheets = pd.ExcelFile(xl_file).sheet_names\n",
    "    workbook = pd.ExcelFile(xl_file)\n",
    "\n",
    "    if fnmatch.fnmatch(xl_file.lower(), \"*grocery*.xlsx\") == True:        \n",
    "        df_grocery = workbook.parse(0)\n",
    "        df_frozen = workbook.parse(1)\n",
    "        df_dairy = workbook.parse(2)\n",
    "#         df_grocery = pd.read_excel(xl_file, find_sheet(sheets, \"grocery\"))\n",
    "#         df_frozen = pd.read_excel(xl_file, find_sheet(sheets, \"frozen\"))\n",
    "#         df_dairy = pd.read_excel(xl_file, find_sheet(sheets, \"dairy\"))\n",
    "    elif fnmatch.fnmatch(xl_file.lower(), \"*hbc*.xlsx\") == True:\n",
    "        df_hbc = workbook.parse(0)\n",
    "    elif fnmatch.fnmatch(xl_file.lower(), \"*perish*.xlsx\") == True:\n",
    "        df_perish = workbook.parse(0)\n",
    "        \n",
    "cs_list = [df_grocery, df_frozen, df_dairy, df_hbc, df_perish]\n",
    "df_cs_data = pd.concat(cs_list)\n",
    "df_cs_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version 2\n",
    "\n",
    "xl_list = glob.glob(data_dir + \"*.xlsx\")\n",
    "cs_list = []\n",
    "\n",
    "for xl_file in xl_list:\n",
    "    workbook = pd.ExcelFile(xl_file)\n",
    "    sheet_list = workbook.sheet_names\n",
    "    \n",
    "    for (index, sheet) in enumerate(sheet_list):\n",
    "        cs_list.append(workbook.parse(index, skiprows=1, header=None))    \n",
    "#     cs_list = [workbook.parse(x) for x, y in enumerate(workbook.sheet_names)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_list = glob.glob(data_dir + \"*.txt\")\n",
    "\n",
    "for txt_file in txt_list:\n",
    "    if fnmatch.fnmatch(txt_file.lower(), \"*mic*.txt\") == True:\n",
    "        df_mic = pd.read_csv(txt_file, sep=\"|\", skiprows=1, header=None)\n",
    "        df_mic.columns = [3, 24, 1, 25]\n",
    "        df_mic.drop(columns=[1], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_mic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cs_data = pd.concat(cs_list)\n",
    "df_cs_data = df_cs_data.merge(df_mic, how=\"left\", on=3)\n",
    "df_cs_data.drop_duplicates(inplace=True)\n",
    "\n",
    "df_cs_data[5] = [\"Rusty Ames\" if x == \"Rusty Amees\" else x for x in df_cs_data[5]]\n",
    "df_cs_data[3] = df_cs_data[3].map('{:0>6}'.format)\n",
    "df_cs_data[6] = df_cs_data[6].map('{:0>6}'.format)\n",
    "\n",
    "df_cs_data = df_cs_data.reindex(df_cs_data.columns.tolist() + [26, 27, 28, 29, 30], axis=1)\n",
    "df_cs_data = df_cs_data[[0, 1, 2, 3, 4, 5, 24, 22, 23, 6, 7, 8, 25, 9, 10, 11, 26, 27, 12, 13, 14, 28, 15, 16, 17, 18, 19, 20, 21, 29, 30]]\n",
    "df_cs_data.columns = ['GL', \n",
    "                      'Location Name', \n",
    "                      'Customer Code', \n",
    "                      'Tops Code', \n",
    "                      'Buyer Code', \n",
    "                      'Category Business Manager', \n",
    "                      'Category', \n",
    "                      'Private Label Flag', \n",
    "                      'Vendor Name', \n",
    "                      'C&S Code', \n",
    "                      'Item Description', \n",
    "                      'Size', \n",
    "                      'Brand', \n",
    "                      'UPC - Vendor', \n",
    "                      'UPC - Case', \n",
    "                      'UPC - Item', \n",
    "                      'WTD Category Unit Lift %', \n",
    "                      'WTD Item Unit Lift %', \n",
    "                      'Weekly Turn (Forecast)', \n",
    "                      'BOH','Total On Order', \n",
    "                      'OOS Yesterday', \n",
    "                      'Next PO Due Date', \n",
    "                      'Next PO Appt Date', \n",
    "                      'Next PO Qty', \n",
    "                      'Next Biceps PO#', \n",
    "                      'Lead Time', \n",
    "                      'Current Week Bookings', \n",
    "                      'Future Bookings', \n",
    "                      'Item Key', \n",
    "                      'Manufacturer Status']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cs_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use code later to clean file\n",
    "\n",
    "# val = df_grocery.iloc[:, [0, 1, 2, 3, 4, 5, 22, 23, 6, 7, 8, 9, 10, 11, 12]]\n",
    "# val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cs_data.to_excel(f\"{archive_dir}CS-Sales-Change-{create_timestamp()}.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "txt_list = glob.glob(data_dir + \"*.txt\")\n",
    "\n",
    "for txt_file in txt_list:\n",
    "    df_wip_sales = pd.read_csv(txt_file, sep=\"~\", header=None)\n",
    "\n",
    "df_wip_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
